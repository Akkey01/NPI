{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $r_i$ and $I_i$ be the population-firing rate and total synaptic input current for population $i$, the firing rate is determined by:\n",
    "$$\n",
    "r_i=F(I_i)=\\cfrac{aI_i-b}{1-\\exp{(-d(aI_i-b))}},\n",
    "$$\n",
    "where $a=270{\\rm Hz/nA}$, $b=108{\\rm Hz}$, $d=0.154{\\rm sec}$.\n",
    "\n",
    "The input current $I_i$ is given by:\n",
    "$$\n",
    "I_i = w J_N S_i + G J_N \\sum ^N_{j=1} C_{ij} S_j + I_{bi},\n",
    "$$\n",
    "where $J_N$ is the overall excitatory strength, $w$ and $G$ scale the strengths of local and long-range interactions, and $S_i$ is the synaptic drive variable.\n",
    "\n",
    "$I_{bi}$ is the background input into population $i$ follows:\n",
    "$$\n",
    "\\tau_0\\cfrac{dI_{bi}}{dt}=-(I_{bi}-I_0)+\\eta_i(t)\\sqrt{\\tau_0\\sigma^2},\n",
    "$$\n",
    "where $I_0$ is the mean of $I_{bi}$, $\\tau_0$ is the filter time constant, $\\sigma$ is the noise amplitude, $\\eta(t)$ is a Gaussian white-noise with zero mean and unit standard deviation.\n",
    "\n",
    "The synaptic drive variable $S_i$ for population $i$ obeys:\n",
    "$$\n",
    "\\cfrac{dS_i}{dt}=F(I_i)\\gamma(1-S_i)-\\cfrac{1}{\\tau_s}S_i,\n",
    "$$\n",
    "where $\\tau_s$ and $\\gamma$ are constants.\n",
    "\n",
    "The BOLD signal $B(t)$ generated by $S_i(t)$ is computed by evaluating the causal convolution of $S_i(t)$ with HRF kernel $f_{bold}(t)$:\n",
    "$$\n",
    "B_i(t)=\\int^t_{-\\infty}S_i(x)f_{bold}(t-x)dx.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(I, a = 270., b = 108., d = 0.154):\n",
    "\n",
    "    \"Transfer function used to determine population-firing rate r with synaptic input I\"\n",
    "    \n",
    "    return (a*I-b) / (1.-np.exp(-d*(a*I-b)))\n",
    "\n",
    "\n",
    "\n",
    "def fbold(t, p = 2, taubold = 1.25, o = 2.25):\n",
    "    \n",
    "    \"Boynton gamma function used as a HRF kernel\"\n",
    "\n",
    "    kernel = np.zeros_like(t)\n",
    "    idx = (t >= o)\n",
    "    kernel[idx] = ((t[idx]-o)/taubold)**(p-1) / math.factorial(p-1) * np.exp(-(t[idx]-o)/taubold)\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = loadmat('./Human_66.mat')\n",
    "C = np.array(load_data['C'])\n",
    "anat_labels = load_data['anat_lbls']\n",
    "order = np.array(load_data['Order'][0]) - 1\n",
    "C = (C[order].T)[order].T\n",
    "anat_labels = anat_labels[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = C                   # structural connectivity\n",
    "N = C.shape[0]          # number of nodes\n",
    "w = 0.55                # self-excitation scaling factor\n",
    "G = 3.5                 # long-range scaling factor\n",
    "JN = 0.2609             # overall excitatory strength\n",
    "I0 = 0.3255             # mean of background input\n",
    "tau0 = 0.002            # noise time constant\n",
    "sigma = 0.005           # noise amplitude\n",
    "tauS = 0.1              # synaptic time constant\n",
    "gamma = 0.641           # saturation factor for gating variable\n",
    "dt = 0.002              # dt of Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_simulation(T, S_start, Ib_start, Ib_in, start, step):\n",
    "\n",
    "    range_t = np.arange(0, T, dt); nt = range_t.size\n",
    "\n",
    "    S = np.zeros((nt, N)); S[0] = S_start\n",
    "    r = np.zeros((nt, N))\n",
    "    B = torch.zeros(nt, N).type(torch.float32).to(device)\n",
    "    IB = np.zeros((nt, N))\n",
    "\n",
    "    fbold_vec = torch.from_numpy(fbold(range_t)[:int(60/dt)]).type(torch.float32)\n",
    "    reversed_fbold_vec = fbold_vec.flip(0).to(device)\n",
    "\n",
    "    I = np.zeros(N); Ib = Ib_start; IB[0] = Ib\n",
    "\n",
    "    for idx in range(1, nt):\n",
    "\n",
    "        I = w * JN * S[idx-1] + G * JN * C @ S[idx-1] + Ib\n",
    "        r[idx] = F(I)\n",
    "        S[idx] = S[idx-1] + dt * (gamma * r[idx] * (1 - S[idx-1]) - S[idx-1] / tauS)\n",
    "        Ib = Ib + (dt / tau0) * (-(Ib - I0) + np.sqrt(tau0) * sigma * Ib_in[idx])\n",
    "        IB[idx] = Ib\n",
    "\n",
    "    S_res = S[start::step]\n",
    "    Ib_res = IB[start::step]\n",
    "    S = torch.from_numpy(S).type(torch.float32).to(device)\n",
    "\n",
    "    for idx in range(N):\n",
    "        \n",
    "        padding_input = torch.nn.functional.pad(S[:, idx], (fbold_vec.size(0)-1, 0), mode = 'constant', value = 0)\n",
    "        B[:, idx] = torch.nn.functional.conv1d(padding_input.view(1, 1, -1), reversed_fbold_vec.view(1, 1, -1))[0][0]\n",
    "    \n",
    "    B_res = B[start::step].detach().cpu().numpy()\n",
    "    \n",
    "    del(S); del(B)\n",
    "\n",
    "    return S_res, Ib_res, B_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for random_seed in range(50):\n",
    "\n",
    "    TR = 0.72; step = int(TR / dt); start = step - 1\n",
    "    T = int(TR * 12000)\n",
    "    S_start = np.zeros(N); r_start = np.zeros(N)\n",
    "    np.random.seed(random_seed)\n",
    "    Ib_in = np.random.randn(int(T/dt), N)\n",
    "    Ib_start = sigma * Ib_in[0]\n",
    "    S_res, Ib_res, B_res = data_simulation(T, S_start, Ib_start, Ib_in, start, step)\n",
    "    np.savetxt('./sim_data/dynamics_raw_T_' + str(T) + '_TR_' + str(int(1000 * TR)) + '_seed_' + '{:03d}'.format(random_seed) + '.txt', B_res)\n",
    "    \n",
    "    pert_step = 500\n",
    "    pert_T = 5\n",
    "    pert_start_list = list(range(2000, B_res.shape[0]-int(pert_T/TR), pert_step))\n",
    "    realEC = np.zeros((N, N))\n",
    "    for pert_start in pert_start_list:\n",
    "        S_start = S_res[pert_start-1]; Ib_start = Ib_res[pert_start-1]\n",
    "        Ib_in_unpert = Ib_in[start+pert_start*step:start+pert_start*step+int(pert_T/dt), :]\n",
    "        _, _, B_unpert = data_simulation(pert_T, S_start, Ib_start, Ib_in_unpert, start, step)\n",
    "        unpert = B_unpert[4]\n",
    "        for i in range(N):\n",
    "            Ib_in_pert = Ib_in_unpert.copy()\n",
    "            perturb = np.zeros(N); perturb[i] = 5.0\n",
    "            Ib_in_pert[:int(0.1/dt)] = Ib_in_pert[:int(0.1/dt)] + perturb\n",
    "            _, _, B_pert = data_simulation(pert_T, S_start, Ib_start, Ib_in_pert, start, step)\n",
    "            realEC[i] = realEC[i] + (B_pert[4] - unpert)\n",
    "    realEC = realEC / len(pert_start_list)\n",
    "    np.savetxt('./sim_data/real_EC_seed_' + '{:03d}'.format(random_seed) + '.txt', realEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
