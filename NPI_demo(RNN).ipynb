{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48546e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import NPI\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58f09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from pathlib import Path; import csv\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def per_roi_std(signals):  # signals: [T,N]\n",
    "    return signals.std(axis=0, ddof=1) + 1e-8\n",
    "\n",
    "def make_snr_vector_uneven(N, center, sigma=0.4, seed=42):\n",
    "    \"\"\"\n",
    "    ROI-wise SNR around a center (5 or 10). Larger sigma = more heterogeneity.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    factors = rng.lognormal(mean=0.0, sigma=sigma, size=N)\n",
    "    factors = np.clip(factors, 0.3, 3.0)          # keep sane\n",
    "    return center * factors\n",
    "\n",
    "def add_noise_by_snr(signals, snr_per_roi):\n",
    "    T, N = signals.shape\n",
    "    sig_std = per_roi_std(signals)\n",
    "    noise_std = sig_std / snr_per_roi\n",
    "    return signals + np.random.randn(T, N) * noise_std\n",
    "\n",
    "def pearson_r(a, b):\n",
    "    a = a.reshape(-1); b = b.reshape(-1)\n",
    "    ma, mb = a.mean(), b.mean()\n",
    "    num = ((a-ma)*(b-mb)).sum()\n",
    "    den = np.sqrt(((a-ma)**2).sum() * ((b-mb)**2).sum()) + 1e-12\n",
    "    return float(num/den)\n",
    "\n",
    "def log_row(path, row):\n",
    "    path = Path(path); path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_header = not path.exists()\n",
    "    with open(path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=row.keys())\n",
    "        if write_header: w.writeheader()\n",
    "        w.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0837c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_LSTM(nn.Module):\n",
    "    def __init__(self, node_dim, hidden=128, num_layers=2, steps=3):\n",
    "        super().__init__()\n",
    "        self.node_dim, self.steps = node_dim, steps\n",
    "        self.enc = nn.Linear(node_dim, hidden)\n",
    "        self.lstm = nn.LSTM(input_size=hidden, hidden_size=hidden,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hidden, node_dim)\n",
    "        self.to(device)\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:               # allow (steps*N,)\n",
    "            x = x.unsqueeze(0)         # -> (1, steps*N)\n",
    "        B = x.shape[0]\n",
    "        seq = x.view(B, self.steps, self.node_dim)\n",
    "        h = torch.relu(self.enc(seq))\n",
    "        h, _ = self.lstm(h)\n",
    "        out = self.out(h[:, -1, :])    # (B, N)\n",
    "        return out[0] if out.shape[0] == 1 else out   # <-- return (N,) for unbatched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4a4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div); pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "    def forward(self, x):  # x: (B,T,D)\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class ANN_Transformer(nn.Module):\n",
    "    def __init__(self, node_dim, d_model=128, nhead=8, num_layers=3, steps=3):\n",
    "        super().__init__()\n",
    "        self.node_dim, self.steps = node_dim, steps\n",
    "        self.inp = nn.Linear(node_dim, d_model)\n",
    "        self.pos = PositionalEncoding(d_model, max_len=steps)\n",
    "        enc = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=num_layers)\n",
    "        self.out = nn.Linear(d_model, node_dim)\n",
    "        self.to(device)\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:               # allow (steps*N,)\n",
    "            x = x.unsqueeze(0)         # -> (1, steps*N)\n",
    "        B = x.shape[0]\n",
    "        seq = x.view(B, self.steps, self.node_dim)   # (B, T, N)\n",
    "        h = self.inp(seq)\n",
    "        h = self.pos(h)\n",
    "        h = self.encoder(h)\n",
    "        out = self.out(h[:, -1, :])    # (B, N)\n",
    "        return out[0] if out.shape[0] == 1 else out   # <-- return (N,) for unbatched               # next-step prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e94db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN_masked(model, input_X, target_Y, steps, p_node=0.15,\n",
    "                    batch_size=64, train_set_proportion=0.8,\n",
    "                    num_epochs=80, lr=5e-4, l2=5e-5):\n",
    "    Xtr = torch.tensor(input_X[:int(train_set_proportion*len(input_X))], dtype=torch.float, device=device)\n",
    "    ytr = torch.tensor(target_Y[:int(train_set_proportion*len(target_Y))], dtype=torch.float, device=device)\n",
    "    Xte = torch.tensor(input_X[int(train_set_proportion*len(input_X)):], dtype=torch.float, device=device)\n",
    "    yte = torch.tensor(target_Y[int(train_set_proportion*len(target_Y)):], dtype=torch.float, device=device)\n",
    "    tr = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(Xtr, ytr), batch_size, shuffle=True)\n",
    "    te = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(Xte, yte), batch_size, shuffle=False)\n",
    "\n",
    "    loss = nn.MSELoss(); opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n",
    "    train_hist, test_hist = [], []\n",
    "    N = ytr.shape[1]\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        model.train()\n",
    "        for xb, yb in tr:\n",
    "            # reshape, mask random ROIs across ~60% of timesteps\n",
    "            B = xb.size(0)\n",
    "            xv = xb.view(B, steps, N)\n",
    "            mask = torch.zeros_like(xv, dtype=torch.bool)\n",
    "            num_nodes = max(1, int(p_node*N))\n",
    "            t_keep = max(1, int(0.4*steps))\n",
    "            t_idx = torch.randint(0, steps, (B, t_keep), device=device)\n",
    "            for b in range(B):\n",
    "                n_idx = torch.randperm(N, device=device)[:num_nodes]\n",
    "                mask[b, :, n_idx] = True\n",
    "                mask[b, t_idx[b], :] = False  # keep some timesteps unmasked\n",
    "            xc = xv.masked_fill(mask, 0.0).view(B, steps*N)\n",
    "\n",
    "            pred = model(xc)\n",
    "            l = loss(pred, yb)\n",
    "            opt.zero_grad(); l.backward(); opt.step()\n",
    "\n",
    "        # epoch eval\n",
    "        model.eval(); tl=0; tn=0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in tr:\n",
    "                tl += loss(model(xb), yb).item()*yb.size(0); tn += yb.size(0)\n",
    "            train_hist.append(tl/tn); tl=0; tn=0\n",
    "            for xb, yb in te:\n",
    "                tl += loss(model(xb), yb).item()*yb.size(0); tn += yb.size(0)\n",
    "            test_hist.append(tl/tn)\n",
    "    return model, train_hist, test_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3498d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_block(model, X, y, steps, true_signals=None, real_EC=None, SC=None):\n",
    "    N = y.shape[1]\n",
    "    out = {}\n",
    "    model_fc = NPI.model_FC(model, node_num=N, steps=steps); out[\"model_fc\"]=model_fc\n",
    "    if true_signals is not None:\n",
    "        emp_fc = NPI.corrcoef(true_signals)\n",
    "        mask = ~np.eye(N, dtype=bool)\n",
    "        out[\"r_fc\"] = pearson_r(model_fc[mask], emp_fc[mask])\n",
    "    ec  = NPI.model_EC(model, X, y, pert_strength=1.0); out[\"ec\"]=ec\n",
    "    jac = NPI.model_Jacobian(model, X, steps=steps);   out[\"jac\"]=jac\n",
    "    if real_EC is not None: out[\"r_ec_real\"]=pearson_r(ec, real_EC); out[\"r_jac_real\"]=pearson_r(jac, real_EC)\n",
    "    if SC is not None:      out[\"r_ec_sc\"]=pearson_r(ec, SC)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3809b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- baseline run config (no noise notebook) ---\n",
    "SEED = 42\n",
    "\n",
    "import random, numpy as np\n",
    "try:\n",
    "    import torch\n",
    "except ImportError:\n",
    "    torch = None\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch:\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15c9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_without_diagonal(matrix):\n",
    "\n",
    "    \"Flatten the matrix without including the diagonal\"\n",
    "    \n",
    "    n = matrix.shape[0]\n",
    "    flattened = []\n",
    "    for i in range(n):\n",
    "        for j in list(range(i)) + list(range(i + 1, n)):\n",
    "            flattened.append(matrix[i][j])\n",
    "    \n",
    "    return np.array(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fd7d2",
   "metadata": {},
   "source": [
    "### **NPI usage demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f82aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size              = 50\n",
    "train_set_proportion    = 0.8\n",
    "ROI_num                 = 20\n",
    "using_steps             = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b472cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds = [0, 1, 42]\n",
    "# for seed in seeds:\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# # load the matching world for this seed (recommended)\n",
    "# signals_clean = np.loadtxt(f'./RNN_simulation_data/sim_data/dynamics_020nodes_8000steps_{seed:02d}seed.txt')\n",
    "# SC      = np.loadtxt(f'./RNN_simulation_data/sim_data/SC_020nodes_8000steps_{seed:02d}seed.txt')\n",
    "# real_EC = np.loadtxt(f'./RNN_simulation_data/sim_data/real_EC_020nodes_8000steps_{seed:02d}seed.txt')\n",
    "\n",
    "# signals = signals_clean.copy()      # clean reference\n",
    "# N = signals_clean.shape[1]\n",
    "# steps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2cb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# # N, steps = 20, 3\n",
    "# dummy = torch.randn(steps*N, device=device)  # 1-D\n",
    "# print(ANN_LSTM(N, steps=steps)(dummy).shape)         # torch.Size([1, N])\n",
    "# print(ANN_Transformer(N, steps=steps)(dummy).shape)  # torch.Size([1, N])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971a935",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# ----- Transformer (baseline) -----\u001b[39;00m\n\u001b[32m     46\u001b[39m tfm = ANN_Transformer(node_dim=N, d_model=\u001b[32m128\u001b[39m, nhead=\u001b[32m8\u001b[39m, num_layers=\u001b[32m3\u001b[39m, steps=steps)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m tfm, tr, te = \u001b[43mNPI\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_NN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m out = eval_block(tfm, X, y, steps, true_signals=signals_clean, real_EC=real_EC, SC=SC)\n\u001b[32m     49\u001b[39m log_row(results_csv, {\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mTransformer\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mSNR_center\u001b[39m\u001b[33m\"\u001b[39m:center,\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m:tr[-\u001b[32m1\u001b[39m],\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m:te[-\u001b[32m1\u001b[39m],\n\u001b[32m     50\u001b[39m                       \u001b[33m\"\u001b[39m\u001b[33mr_fc\u001b[39m\u001b[33m\"\u001b[39m:out.get(\u001b[33m\"\u001b[39m\u001b[33mr_fc\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\u001b[33m\"\u001b[39m\u001b[33mr_ec_real\u001b[39m\u001b[33m\"\u001b[39m:out.get(\u001b[33m\"\u001b[39m\u001b[33mr_ec_real\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     51\u001b[39m                       \u001b[33m\"\u001b[39m\u001b[33mr_jac_real\u001b[39m\u001b[33m\"\u001b[39m:out.get(\u001b[33m\"\u001b[39m\u001b[33mr_jac_real\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m),\u001b[33m\"\u001b[39m\u001b[33mr_ec_sc\u001b[39m\u001b[33m\"\u001b[39m:out.get(\u001b[33m\"\u001b[39m\u001b[33mr_ec_sc\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aksha\\Documents\\Github repos\\NPI\\NPI.py:130\u001b[39m, in \u001b[36mtrain_NN\u001b[39m\u001b[34m(model, input_X, target_Y, batch_size, train_set_proportion, num_epochs, lr, l2)\u001b[39m\n\u001b[32m    128\u001b[39m     trainer.zero_grad()\n\u001b[32m    129\u001b[39m     l.backward()\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m model.eval()\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aksha\\Documents\\Github repos\\NPI\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    382\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    383\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aksha\\Documents\\Github repos\\NPI\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m'\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     75\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aksha\\Documents\\Github repos\\NPI\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:166\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    155\u001b[39m     beta1, beta2 = group[\u001b[33m'\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    157\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    158\u001b[39m         group,\n\u001b[32m    159\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    163\u001b[39m         max_exp_avg_sqs,\n\u001b[32m    164\u001b[39m         state_steps)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aksha\\Documents\\Github repos\\NPI\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:316\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    314\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aksha\\Documents\\Github repos\\NPI\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:391\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    388\u001b[39m     param = torch.view_as_real(param)\n\u001b[32m    390\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[43mexp_avg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "seeds = [0, 1, 42]\n",
    "\n",
    "Path(\"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "results_csv = \"metrics/uneven_snr_5_10_mlp_lstm_mask.csv\"\n",
    "\n",
    "for seed in seeds:\n",
    "    # set RNGs\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # --- load matching world for THIS seed ---\n",
    "    signals_clean = np.loadtxt(f'./RNN_simulation_data/sim_data/dynamics_020nodes_8000steps_{seed:02d}seed.txt')\n",
    "    SC      = np.loadtxt(f'./RNN_simulation_data/sim_data/SC_020nodes_8000steps_{seed:02d}seed.txt')\n",
    "    real_EC = np.loadtxt(f'./RNN_simulation_data/sim_data/real_EC_020nodes_8000steps_{seed:02d}seed.txt')\n",
    "\n",
    "    N = signals_clean.shape[1]\n",
    "    steps = 3\n",
    "\n",
    "    # ---- run experiments for both SNR centers for THIS seed ----\n",
    "    for center in [5, 10]:\n",
    "        snr_vec = make_snr_vector_uneven(N, center=center, sigma=0.4, seed=seed)\n",
    "        noisy = add_noise_by_snr(signals_clean, snr_vec)\n",
    "        X, y = NPI.multi2one(noisy, steps)\n",
    "\n",
    "        # MLP (no mask)\n",
    "        mlp = NPI.ANN_MLP(input_dim=steps*N, hidden_dim=int(2.5*N), latent_dim=int(0.8*N), output_dim=N)\n",
    "        mlp, tr, te = NPI.train_NN(mlp, X, y, num_epochs=80, lr=1e-3, l2=5e-5)\n",
    "        out = eval_block(mlp, X, y, steps, true_signals=signals_clean, real_EC=real_EC, SC=SC)\n",
    "        log_row(results_csv, {\"seed\": seed,\"model\":\"MLP\",\"mask\":\"no\",\"SNR_center\":center,\n",
    "                              \"train\":tr[-1],\"test\":te[-1],\n",
    "                              \"r_fc\":out.get(\"r_fc\",\"\"),\"r_ec_real\":out.get(\"r_ec_real\",\"\"),\n",
    "                              \"r_jac_real\":out.get(\"r_jac_real\",\"\"),\"r_ec_sc\":out.get(\"r_ec_sc\",\"\")})\n",
    "\n",
    "        # MLP (mask)\n",
    "        mlp_m = NPI.ANN_MLP(input_dim=steps*N, hidden_dim=int(2.5*N), latent_dim=int(0.8*N), output_dim=N)\n",
    "        mlp_m, tr, te = train_NN_masked(mlp_m, X, y, steps, p_node=0.15, num_epochs=80, lr=1e-3, l2=5e-5)\n",
    "        out = eval_block(mlp_m, X, y, steps, true_signals=signals_clean, real_EC=real_EC, SC=SC)\n",
    "        log_row(results_csv, {\"seed\": seed,\"model\":\"MLP\",\"mask\":\"yes\",\"SNR_center\":center,\n",
    "                              \"train\":tr[-1],\"test\":te[-1],\n",
    "                              \"r_fc\":out.get(\"r_fc\",\"\"),\"r_ec_real\":out.get(\"r_ec_real\",\"\"),\n",
    "                              \"r_jac_real\":out.get(\"r_jac_real\",\"\"),\"r_ec_sc\":out.get(\"r_ec_sc\",\"\")})\n",
    "\n",
    "        # LSTM (no mask)\n",
    "        lstm = ANN_LSTM(node_dim=N, hidden=128, num_layers=2, steps=steps)\n",
    "        lstm, tr, te = NPI.train_NN(lstm, X, y, num_epochs=80, lr=5e-4, l2=5e-5)\n",
    "        out = eval_block(lstm, X, y, steps, true_signals=signals_clean, real_EC=real_EC, SC=SC)\n",
    "        log_row(results_csv, {\"seed\": seed,\"model\":\"LSTM\",\"mask\":\"no\",\"SNR_center\":center,\n",
    "                              \"train\":tr[-1],\"test\":te[-1],\n",
    "                              \"r_fc\":out.get(\"r_fc\",\"\"),\"r_ec_real\":out.get(\"r_ec_real\",\"\"),\n",
    "                              \"r_jac_real\":out.get(\"r_jac_real\",\"\"),\"r_ec_sc\":out.get(\"r_ec_sc\",\"\")})\n",
    "\n",
    "        # LSTM (mask)\n",
    "        lstm_m = ANN_LSTM(node_dim=N, hidden=128, num_layers=2, steps=steps)\n",
    "        lstm_m, tr, te = train_NN_masked(lstm_m, X, y, steps, p_node=0.15, num_epochs=80, lr=5e-4, l2=5e-5)\n",
    "        out = eval_block(lstm_m, X, y, steps, true_signals=signals_clean, real_EC=real_EC, SC=SC)\n",
    "        log_row(results_csv, {\"seed\": seed,\"model\":\"LSTM\",\"mask\":\"yes\",\"SNR_center\":center,\n",
    "                              \"train\":tr[-1],\"test\":te[-1],\n",
    "                              \"r_fc\":out.get(\"r_fc\",\"\"),\"r_ec_real\":out.get(\"r_ec_real\",\"\"),\n",
    "                              \"r_jac_real\":out.get(\"r_jac_real\",\"\"),\"r_ec_sc\":out.get(\"r_ec_sc\",\"\")})\n",
    "\n",
    "        # Transformer (no mask)\n",
    "        tfm = ANN_Transformer(node_dim=N, d_model=128, nhead=8, num_layers=3, steps=steps)\n",
    "        tfm, tr, te = NPI.train_NN(tfm, X, y, num_epochs=80, lr=5e-4, l2=5e-5)\n",
    "        out = eval_block(tfm, X, y, steps, true_signals=signals_clean, real_EC=real_EC, SC=SC)\n",
    "        log_row(results_csv, {\"seed\": seed,\"model\":\"Transformer\",\"mask\":\"no\",\"SNR_center\":center,\n",
    "                              \"train\":tr[-1],\"test\":te[-1],\n",
    "                              \"r_fc\":out.get(\"r_fc\",\"\"),\"r_ec_real\":out.get(\"r_ec_real\",\"\"),\n",
    "                              \"r_jac_real\":out.get(\"r_jac_real\",\"\"),\"r_ec_sc\":out.get(\"r_ec_sc\",\"\")})\n",
    "\n",
    "        # Transformer (mask)\n",
    "        tfm_m = ANN_Transformer(node_dim=N, d_model=128, nhead=8, num_layers=3, steps=steps)\n",
    "        tfm_m, tr, te = train_NN_masked(tfm_m, X, y, steps, p_node=0.15, num_epochs=80, lr=5e-4, l2=5e-5)\n",
    "        out = eval_block(tfm_m, X, y, steps, true_signals=signals_clean, real_EC=real_EC, SC=SC)\n",
    "        log_row(results_csv, {\"seed\": seed,\"model\":\"Transformer\",\"mask\":\"yes\",\"SNR_center\":center,\n",
    "                              \"train\":tr[-1],\"test\":te[-1],\n",
    "                              \"r_fc\":out.get(\"r_fc\",\"\"),\"r_ec_real\":out.get(\"r_ec_real\",\"\"),\n",
    "                              \"r_jac_real\":out.get(\"r_jac_real\",\"\"),\"r_ec_sc\":out.get(\"r_ec_sc\",\"\")})\n",
    "# end for seed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b983f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CONTROL FLAGS ======\n",
    "RUN_OLD_DEMO = False          # <- set to True if you want to see the old single-seed demo again\n",
    "RUN_GROUP_BASELINE = False    # <- set to True if you want the 50-seed baseline loop\n",
    "# ===========================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6c843",
   "metadata": {},
   "source": [
    "##### train NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bc080",
   "metadata": {},
   "source": [
    "Several ANNs (MLP, CNN, RNN, VAR) are provided in the NPI framework, which can be used as a surrogate brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15803cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = NPI.multi2one(signals, steps = using_steps)\n",
    "\n",
    "ANN = NPI.ANN_MLP(input_dim = using_steps * ROI_num, hidden_dim = 2 * ROI_num, latent_dim = int(0.8 * ROI_num), output_dim = ROI_num)\n",
    "# ANN = NPI.ANN_CNN(in_channels = ROI_num, hidden_channels = 3 * ROI_num, out_channels = ROI_num, data_length = using_steps)\n",
    "# ANN = NPI.ANN_RNN(input_dim = ROI_num, hidden_dim = int(2.5 * ROI_num), latent_dim = int(2.5 * ROI_num), output_dim = ROI_num, data_length = using_steps)\n",
    "# ANN = NPI.ANN_VAR(input_dim = using_steps * ROI_num, output_dim = ROI_num)\n",
    "\n",
    "ANN, training_loss, testing_loss = NPI.train_NN(ANN, inputs, targets, batch_size, train_set_proportion, num_epochs = 80, lr = 2e-4, l2 = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d790649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_loss, label = 'Training loss')\n",
    "plt.plot(testing_loss, label = 'Testing loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c56064c",
   "metadata": {},
   "source": [
    "##### calculate empirical FC & model FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_FC = NPI.corrcoef(signals)\n",
    "model_FC = NPI.model_FC(ANN, node_num = ROI_num, steps = using_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff3a0b",
   "metadata": {},
   "source": [
    "##### calculate NPI Inferred EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083051ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPI_EC = NPI.model_EC(ANN, inputs, targets, pert_strength = 1.0)\n",
    "np.fill_diagonal(NPI_EC, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3971cdf2",
   "metadata": {},
   "source": [
    "##### calculate model Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPI_Jacobian = NPI.model_Jacobian(ANN, inputs, steps = using_steps)\n",
    "np.fill_diagonal(NPI_Jacobian, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787875dc",
   "metadata": {},
   "source": [
    "##### empirical FC - model FC comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "sns.heatmap(empirical_FC, ax = ax1, vmin = -0.5, vmax = 0.5, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "sns.heatmap(model_FC, ax = ax2, vmin = -1.0, vmax = 1.0, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "ax1.set_title('Empirical FC'); ax2.set_title('Model FC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af1a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_value, p_value = pearsonr(flat_without_diagonal(model_FC), flat_without_diagonal(empirical_FC))\n",
    "\n",
    "plt.figure(figsize = (4.8, 4.8))\n",
    "plt.scatter(flat_without_diagonal(model_FC), flat_without_diagonal(empirical_FC))\n",
    "\n",
    "plt.xlim(-1.05, 1.05); plt.xticks([-1.0, 0.0, 1.0]); plt.xlabel('model FC')\n",
    "plt.ylim(-0.55, 0.55); plt.yticks([-0.5, 0.0, 0.5]); plt.ylabel('empirical FC')\n",
    "plt.text(-0.95, 0.45, 'r = {:.2f}, p = {:.0e}'.format(r_value, p_value))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False); ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824297",
   "metadata": {},
   "source": [
    "##### real EC - NPI EC comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "sns.heatmap(real_EC, ax = ax1, vmin = -0.2, vmax = 0.2, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "sns.heatmap(NPI_EC, ax = ax2, vmin = -0.2, vmax = 0.2, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "ax1.set_title('Real EC'); ax2.set_title('NPI Inferred EC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_value, p_value = pearsonr(flat_without_diagonal(NPI_EC), flat_without_diagonal(real_EC))\n",
    "\n",
    "plt.figure(figsize = (4.8, 4.8))\n",
    "plt.scatter(flat_without_diagonal(NPI_EC), flat_without_diagonal(real_EC))\n",
    "\n",
    "plt.xlim(-0.25, 0.25); plt.xticks([-0.2, 0.0, 0.2]); plt.xlabel('NPI Inferred EC')\n",
    "plt.ylim(-0.25, 0.25); plt.yticks([-0.2, 0.0, 0.2]); plt.ylabel('Real EC')\n",
    "plt.text(-0.2, 0.2, 'r = {:.2f}, p = {:.0e}'.format(r_value, p_value))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False); ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1f381",
   "metadata": {},
   "source": [
    "##### real EC - model Jacobian comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "sns.heatmap(real_EC, ax = ax1, vmin = -0.2, vmax = 0.2, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "sns.heatmap(NPI_Jacobian, ax = ax2, vmin = -0.2, vmax = 0.2, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "ax1.set_title('Real EC'); ax2.set_title('Model Jacobian')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d10113",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_value, p_value = pearsonr(flat_without_diagonal(NPI_Jacobian), flat_without_diagonal(real_EC))\n",
    "\n",
    "plt.figure(figsize = (4.8, 4.8))\n",
    "plt.scatter(flat_without_diagonal(NPI_Jacobian), flat_without_diagonal(real_EC))\n",
    "\n",
    "plt.xlim(-0.25, 0.25); plt.xticks([-0.2, 0.0, 0.2]); plt.xlabel('Model Jacobian')\n",
    "plt.ylim(-0.25, 0.25); plt.yticks([-0.2, 0.0, 0.2]); plt.ylabel('Real EC')\n",
    "plt.text(-0.2, 0.2, 'r = {:.2f}, p = {:.0e}'.format(r_value, p_value))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False); ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d378a0",
   "metadata": {},
   "source": [
    "##### SC - NPI EC comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f863ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "sns.heatmap(SC, ax = ax1, vmin = -0.7, vmax = 0.7, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "sns.heatmap(NPI_EC, ax = ax2, vmin = -0.2, vmax = 0.2, cmap = 'RdBu_r', cbar = False, square = True, xticklabels = False, yticklabels = False)\n",
    "ax1.set_title('SC'); ax2.set_title('NPI Inferred EC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf982a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_value, p_value = pearsonr(flat_without_diagonal(NPI_EC), flat_without_diagonal(SC))\n",
    "\n",
    "plt.figure(figsize = (4.8, 4.8))\n",
    "plt.scatter(flat_without_diagonal(NPI_EC), flat_without_diagonal(SC))\n",
    "\n",
    "plt.xlim(-0.25, 0.25); plt.xticks([-0.2, 0.0, 0.2]); plt.xlabel('NPI Inferred EC')\n",
    "plt.ylim(-0.75, 0.75); plt.yticks([-0.7, 0.0, 0.7]); plt.ylabel('SC')\n",
    "plt.text(-0.2, 0.6, 'r = {:.2f}, p = {:.0e}'.format(r_value, p_value))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False); ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9516ba",
   "metadata": {},
   "source": [
    "##### Group-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPIFC_empiricalFC_corr = []\n",
    "NPIEC_realEC_corr = []\n",
    "NPIEC_SC_corr = []\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    signals = np.loadtxt('./RNN_simulation_data/sim_data/dynamics_020nodes_8000steps_{:02d}seed.txt'.format(i))\n",
    "    SC      = np.loadtxt('./RNN_simulation_data/sim_data/SC_020nodes_8000steps_{:02d}seed.txt'.format(i))\n",
    "    real_EC = np.loadtxt('./RNN_simulation_data/sim_data/real_EC_020nodes_8000steps_{:02d}seed.txt'.format(i))\n",
    "\n",
    "    inputs, targets = NPI.multi2one(signals, steps = 3)\n",
    "    ANN = NPI.ANN_MLP(input_dim = using_steps * ROI_num, hidden_dim = 2 * ROI_num, latent_dim = int(0.8 * ROI_num), output_dim = ROI_num)\n",
    "    ANN, training_loss, testing_loss = NPI.train_NN(ANN, inputs, targets, num_epochs = 80, lr = 2e-4, l2 = 5e-5)\n",
    "\n",
    "    empirical_FC = NPI.corrcoef(signals)\n",
    "    model_FC = NPI.model_FC(ANN, node_num = ROI_num, steps = 3)\n",
    "    NPIFC_empiricalFC_corr.append(pearsonr(flat_without_diagonal(model_FC), flat_without_diagonal(empirical_FC))[0])\n",
    "\n",
    "    NPI_EC = NPI.model_EC(ANN, inputs, targets, pert_strength = 1.0)\n",
    "    np.fill_diagonal(NPI_EC, 0)\n",
    "    NPIEC_realEC_corr.append(pearsonr(flat_without_diagonal(NPI_EC), flat_without_diagonal(real_EC))[0])\n",
    "    NPIEC_SC_corr.append(pearsonr(flat_without_diagonal(NPI_EC), flat_without_diagonal(SC))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['NPI FC -\\n real FC', 'NPI EC -\\n real EC', 'NPI EC -\\n SC']\n",
    "values = [np.mean(NPIFC_empiricalFC_corr), np.mean(NPIEC_realEC_corr), np.mean(NPIEC_SC_corr)]\n",
    "stds = [np.std(NPIFC_empiricalFC_corr), np.std(NPIEC_realEC_corr), np.std(NPIEC_SC_corr)]\n",
    "\n",
    "plt.figure(figsize = (3, 3))\n",
    "plt.bar(categories, values, yerr = stds, capsize = 5)\n",
    "plt.ylabel('Pearson Correlation')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False); ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa0b25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "def pick(*names):\n",
    "    g = globals()\n",
    "    for n in names:\n",
    "        if n in g:\n",
    "            return g[n]\n",
    "    raise NameError(f\"Could not find any of: {names}\")\n",
    "\n",
    "def upper_tri(m):\n",
    "    m = np.asarray(m)\n",
    "    i = np.triu_indices_from(m, k=1)\n",
    "    return m[i]\n",
    "\n",
    "def fc_corr_from_any(emp_fc, mdl_fc):\n",
    "    a = upper_tri(emp_fc)\n",
    "    b = upper_tri(mdl_fc)\n",
    "    return float(np.corrcoef(a, b)[0, 1])\n",
    "\n",
    "# Try common names used in FC comparison cells\n",
    "emp_fc = pick(\"empirical_FC\", \"empirical_fc\", \"FC_empirical\", \"FC_emp\")\n",
    "mdl_fc = pick(\"model_FC\", \"model_fc\", \"FC_model\", \"fc_model\")\n",
    "\n",
    "fc_corr = fc_corr_from_any(emp_fc, mdl_fc)\n",
    "\n",
    "row = {\n",
    "    \"demo\": \"RNN\",          # change to \"WBM\" if you're in that notebook\n",
    "    \"snr\": \"baseline\",\n",
    "    \"mode\": \"none\",\n",
    "    \"seed\": SEED,\n",
    "    \"metric\": \"fc_corr\",\n",
    "    \"value\": fc_corr,\n",
    "}\n",
    "csv_path = \"results_snr_sweep.csv\"\n",
    "pd.DataFrame([row]).to_csv(csv_path, mode=\"a\", header=not os.path.exists(csv_path), index=False)\n",
    "print(\"Appended to\", csv_path, row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6dbb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Plots for inference from uneven-SNR experiments ===\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(\"metrics/uneven_snr_5_10_mlp_lstm_mask.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Canonical order for models/masks\n",
    "order = [(\"MLP\",\"no\"),(\"MLP\",\"yes\"),\n",
    "         (\"LSTM\",\"no\"),(\"LSTM\",\"yes\"),\n",
    "         (\"Transformer\",\"no\"),(\"Transformer\",\"yes\")]\n",
    "\n",
    "metrics = [\"r_fc\",\"r_ec_real\",\"r_jac_real\",\"r_ec_sc\"]\n",
    "\n",
    "# Save dir\n",
    "plot_dir = Path(\"metrics/graphs\"); plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for snr in sorted(df[\"SNR_center\"].unique()):\n",
    "    sub = df[df[\"SNR_center\"]==snr]\n",
    "    for metric in metrics:\n",
    "        if metric not in sub.columns: continue\n",
    "        plt.figure(figsize=(8,4))\n",
    "        means = []\n",
    "        stds  = []\n",
    "        labels = []\n",
    "        for model,mask in order:\n",
    "            vals = sub[(sub[\"model\"]==model)&(sub[\"mask\"]==mask)][metric].dropna()\n",
    "            if len(vals)==0: continue\n",
    "            means.append(vals.mean()); stds.append(vals.std(ddof=1)); labels.append(f\"{model}|{mask}\")\n",
    "        x = range(len(means))\n",
    "        plt.bar(x, means, yerr=stds, capsize=4)\n",
    "        plt.xticks(x, labels, rotation=30, ha=\"right\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f\"{metric} @ SNR {snr} (mean ± std over seeds)\")\n",
    "        plt.tight_layout()\n",
    "        outpath = plot_dir / f\"{metric}_SNR{snr}.png\"\n",
    "        plt.savefig(outpath, dpi=200)\n",
    "        plt.show()\n",
    "        print(\"Saved:\", outpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2717f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ All experiments complete. Plots saved in metrics/graphs/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
